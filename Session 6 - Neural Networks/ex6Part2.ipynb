{"cells":[{"cell_type":"markdown","metadata":{"id":"GIPm7lABRijv"},"source":["# Tutorial 6 (Introduction to AI)\n","\n","# Neural Networks: MLP (Part 2)"]},{"cell_type":"markdown","metadata":{"id":"vT1-ijoaRij4"},"source":["## 2. Neural Network classification using Iris\n","\n","This second example revisits the iris dataset for multi-classification. The key point to note for classification is that since there are three classes, the network needs three outputs, each 0/1, and the output needs to be one-hot encoded.\n","\n","Two of the helper functions are used here, so they are included.  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ncyVt4vcRij8"},"outputs":[],"source":["import base64\n","import os\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import requests\n","from sklearn import preprocessing\n","\n","# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n","def encode_text_index(df, name):\n","    le = preprocessing.LabelEncoder()\n","    df[name] = le.fit_transform(df[name])\n","    return le.classes_\n","\n","# Convert a Pandas dataframe to the X,y inputs that Keras needs\n","def to_xy(df, target):\n","    result = []\n","    for x in df.columns:\n","        if x != target:\n","            result.append(x)\n","    # find out the type of the target column.  Is it really this hard? :(\n","    target_type = df[target].dtypes\n","    target_type = target_type[0] if hasattr(\n","        target_type, '__iter__') else target_type\n","    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n","    if target_type in (np.int64, np.int32):\n","        # Classification\n","        dummies = pd.get_dummies(df[target])\n","        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n","    # Regression\n","    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)"]},{"cell_type":"markdown","metadata":{"id":"uoR0CggmRikE"},"source":["As noted above, for classification, as compared to regression, the major difference is the output layer.  For regression a single unit computes a linear combination of its input to produce an output value, whereas a classification network needs to decide which of several classes to categorise an input to.  This is achieved by having an output node for each class. These are then considered together with an output **softmax** activation function which results in an output which is the probability of the input belonging to that class.  The loss function for classification network is typicall **categorical crossentropy** (also called **logloss**).\n","\n","In the example below using the iris dataset, you can see this illustrated in the context of 5-fold cross-validation.  The number of hidden units, and the number of epochs has here been selected to work well, but you should experiment with changing the values, perhaps also adding another hidden layer.\n","\n","The species names have been encoded as integers using the encode_text_index method (which is in turn using LabelEncoder).  An alternative using keras's to_categorical is also included."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"MBOt_E_7RikF","outputId":"cadb96c8-19bf-43f2-8d54-8d9418fe4ff8"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]]\n","Accuracy score: 1.0\n","Accuracy score: 0.9666666666666667\n","Accuracy score: 0.9666666666666667\n","Accuracy score: 0.9333333333333333\n","Accuracy score: 1.0\n"]}],"source":["import pandas as pd\n","import io\n","import requests\n","import numpy as np\n","import os\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from sklearn import metrics\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","path = \"../ex1/\"\n","\n","filename = os.path.join(path,\"iris.csv\")\n","df = pd.read_csv(filename,na_values=['NA','?'])\n","\n","np.random.seed(42)\n","df = df.reindex(np.random.permutation(df.index))\n","\n","species = encode_text_index(df,\"species\")\n","X,y = to_xy(df,\"species\")\n","\n","#or directly, using LabelEncoder to transform text to integers, then\n","#to_categorical to one hot encode\n","#le = preprocessing.LabelEncoder()\n","#df['species'] = le.fit_transform(df['species'])\n","#y = keras.utils.to_categorical(df['species'].to_numpy())\n","#X = df.drop(columns=['species']).to_numpy()\n","\n","#Let's look at y\n","print(y)\n","\n","model = Sequential()\n","model.add(Dense(64, input_dim=X.shape[1], activation='relu'))\n","model.add(Dense(y.shape[1],activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\n","\n","kf = KFold(5)\n","\n","for train, test in kf.split(X):\n","    X_train = X[train]\n","    y_train = y[train]\n","    X_test = X[test]\n","    y_test = y[test]\n","\n","    model.fit(X_train,y_train,verbose=0,epochs=128)\n","    pred = model.predict(X_test)\n","    pred = np.argmax(pred,axis=1)\n","    y_compare = np.argmax(y_test,axis=1)\n","    score = metrics.accuracy_score(y_compare, pred)\n","    print(\"Accuracy score: {}\".format(score))"]},{"cell_type":"markdown","metadata":{"id":"kTy0D0EgRikK"},"source":["The iris dataset has three classes, so the output from the network consists of three values, one from each output layer node (corresponding to each class).  This number is a probability, so the prediction from this model consist of triples, as below:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eEZTYjmPRikL","outputId":"adca7897-80ca-44b9-f5c5-0f605a51e497"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[2.50053126e-04 9.90728140e-01 9.02187731e-03]\n"," [9.99599040e-01 4.00970079e-04 1.88016412e-14]\n"," [3.28531126e-11 1.46591647e-05 9.99985337e-01]\n"," [2.34782652e-04 9.54570949e-01 4.51943502e-02]\n"," [1.32247034e-04 9.89701867e-01 1.01658702e-02]\n"," [9.99147892e-01 8.52144381e-04 2.26842823e-13]\n"," [3.14013660e-03 9.96376216e-01 4.83677810e-04]\n"," [8.31776617e-07 2.43404061e-02 9.75658774e-01]\n"," [1.00703895e-04 6.67842686e-01 3.32056671e-01]\n"," [1.00772548e-03 9.98267412e-01 7.24902144e-04]]\n"]}],"source":["from sklearn import metrics\n","\n","pred = model.predict(X) # using all the data\n","print(pred[0:10]) # print first ten predictions"]},{"cell_type":"markdown","metadata":{"id":"Pm9Qfw_DRikO"},"source":["In my run of this, the first row says: [2.50053126e-04 9.90728140e-01 9.02187731e-03].  That is class 0 is very unlikely to occur with miniscule probability, class 1 has probability of about 99.1%, and class two probability of  less than 1%.  The output prediction here is then class 1 (see below).  Notice that we might potentially ask for a second choice, and that we have data to allow us to make this second choice."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A6aI5mvMRikP","outputId":"bf595ab9-13e7-4672-eb9a-a39223bf8cc6"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n"," 0 0 0 2 1 1 0 0 1 1 2 1 2 1 2 1 0 2 1 0 0 0 1 2 0 0 0 1 0 1 2 0 1 2 0 2 2\n"," 1 1 2 1 0 1 2 0 0 1 1 0 2 0 0 2 1 2 2 2 2 1 0 0 2 2 0 0 0 1 2 0 2 2 0 1 1\n"," 2 1 2 0 2 1 2 1 1 1 0 1 1 0 1 2 2 0 1 2 2 0 2 0 1 2 2 1 2 1 1 2 2 0 1 2 0\n"," 1 2]\n","[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n"," 0 0 0 2 1 1 0 0 1 2 2 1 2 1 2 1 0 2 1 0 0 0 1 2 0 0 0 1 0 1 2 0 1 2 0 2 2\n"," 1 1 2 1 0 1 2 0 0 1 1 0 2 0 0 1 1 2 1 2 2 1 0 0 2 2 0 0 0 1 2 0 2 2 0 1 1\n"," 2 1 2 0 2 1 2 1 1 1 0 1 1 0 1 2 2 0 1 2 2 0 2 0 1 2 2 1 2 1 1 2 2 0 1 2 0\n"," 1 2]\n"]}],"source":["print(np.argmax(pred,axis=1))\n","print(np.argmax(y,axis=1))"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"Xs2mekhgRikR"},"source":["## Load/Save trained network\n","\n","Complex neural networks will take a long time to fit/train.  It is helpful to be able to save these neural networks so that they can be reloaded later.  A reloaded neural network will not require retraining.  Keras provides at least two formats for neural network saving.\n","\n","* **JSON** - Stores the neural network structure (no weights) in the [JSON file format](https://en.wikipedia.org/wiki/JSON).\n","* **HDF5** - Stores the complete neural network (with weights) in the [HDF5 file format](https://en.wikipedia.org/wiki/Hierarchical_Data_Format). Do not confuse HDF5 with [HDFS](https://en.wikipedia.org/wiki/Apache_Hadoop).  They are different.  We do not use HDFS in this class.\n","\n","Usually you will want to save in HDF5."]},{"cell_type":"markdown","metadata":{"id":"Di0KrAU7RikS"},"source":["The code below sets up a neural network and reads the data (for predictions), but it does not clear the model directory or fit the neural network.  The weights from the previous fit are used."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QYlWqakERikT","outputId":"989dcce9-61d6-458d-a1cb-319cbdcc794b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy score: 1.0\n"]}],"source":["X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n","\n","model = Sequential()\n","model.add(Dense(64, input_dim=X.shape[1], activation='relu'))\n","model.add(Dense(10))\n","model.add(Dense(y.shape[1],activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\n","model.fit(X_train,y_train,verbose=0,epochs=128)\n","pred = model.predict(X_test)\n","pred = np.argmax(pred,axis=1)\n","y_compare = np.argmax(y_test,axis=1)\n","score = metrics.accuracy_score(y_compare, pred)\n","print(\"Accuracy score: {}\".format(score))\n","\n","#path to where the file will be saved\n","save_path = \".\"\n","\n","# save neural network structure to JSON (no weights)\n","model_json = model.to_json()\n","with open(os.path.join(save_path,\"network.json\"), \"w\") as json_file:\n","    json_file.write(model_json)\n","\n","# save entire network to HDF5 (save everything, suggested)\n","model.save(os.path.join(save_path,\"network.h5\"))"]},{"cell_type":"markdown","metadata":{"id":"aQPVlK4lRikU"},"source":["Now we reload the network and perform another prediction.  The Accuracy score should match the previous one exactly if the neural network was really saved and reloaded."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pYbzpoArRikV","outputId":"0f932d56-0017-4aa8-99ae-b2cd81733804"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy score: 1.0\n"]}],"source":["from tensorflow.keras.models import load_model\n","model2 = load_model(os.path.join(save_path,\"network.h5\"))\n","pred = model2.predict(X_test)\n","pred = np.argmax(pred,axis=1)\n","y_compare = np.argmax(y_test,axis=1)\n","score = metrics.accuracy_score(y_compare, pred)\n","print(\"Accuracy score: {}\".format(score))"]},{"cell_type":"markdown","metadata":{"id":"6dzdJeKzRikW"},"source":["## Exercises\n","\n","1. Use the sklearn digits dataset (sklearn.load_digits()) and build a neural network classifier for this dataset.  You might need to use tensorflow.keras.utils and in particular to_categorical() in order to treat the target labels correctly as a one-hot encoding."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3u9aPOlSRikW"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}