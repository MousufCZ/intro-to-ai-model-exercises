{"cells":[{"cell_type":"markdown","metadata":{"id":"BEwcD5SDRqHx"},"source":["# Tutorial 7 (Introduction to AI)\n","\n","# MLP. Training neural networks"]},{"cell_type":"markdown","metadata":{"id":"u3Bzw_5CRqH1"},"source":["# Part 1. Early Stopping and Regularization techniques\n"]},{"cell_type":"markdown","metadata":{"id":"M30rz8x7RqH3"},"source":["Training a deep neural network that can generalize well to new data is a challenging problem.\n","\n","A model with too little capacity cannot learn the problem, whereas a model with too much capacity can learn it too well and overfit the training dataset. Both cases result in a model that does not generalize well.\n","\n","This motivates the use of **regularisation** during training in order to reduce the generalization error.  The application of these techniques might give a larger model, but not only reduce overfitting, they can also lead to faster optimization of the model and better overall performance."]},{"cell_type":"markdown","metadata":{"id":"j1IugrbWRqH3"},"source":["## 1. Early stopping\n","\n","Before we look at regularisation, we will pause to look at one commonly used training technique.\n","\n","Training neural networks can be expensive, it terms of time and resource.  In last week's exercises we specified the number of epochs training was to run for, set it running and left it at that.  This might mean leaving the network training once it has converged to a solution.  This will lead to unnecessary training time, and possibly to overfitting.\n","\n","This motivates *early stopping*, where a stopping criteria (in terms of the error) is specified and once this criteria is met, training ceases.\n","\n","In Keras this is specified as a callback, and you might need to set the following parameters:\n","\n","* monitor -- what quantity is being measure, typically *loss*\n","* min_delta -- a change in the monitor less than this value doesn't count as an improvement\n","* patience -- the number of epochs of no improvement to trigger early stopping\n","* mode -- typically *auto*\n","\n","We will now apply this to the auto_mpg example we looked at last week.  First, we include the helper functions again."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_XZjLlPzRqH4"},"outputs":[],"source":["import base64\n","import os\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import requests\n","from sklearn import preprocessing\n","\n","# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n","def encode_text_dummy(df, name):\n","    dummies = pd.get_dummies(df[name])\n","    for x in dummies.columns:\n","        dummy_name = f\"{name}-{x}\"\n","        df[dummy_name] = dummies[x]\n","    df.drop(name, axis=1, inplace=True)\n","\n","# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n","# at every location where the original column (name) matches each of the target_values.  One column is added for\n","# each target value.\n","def encode_text_single_dummy(df, name, target_values):\n","    for tv in target_values:\n","        l = list(df[name].astype(str))\n","        l = [1 if str(x) == str(tv) else 0 for x in l]\n","        name2 = f\"{name}-{tv}\"\n","        df[name2] = l\n","\n","# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n","def encode_text_index(df, name):\n","    le = preprocessing.LabelEncoder()\n","    df[name] = le.fit_transform(df[name])\n","    return le.classes_\n","\n","# Encode a numeric column as zscores\n","def encode_numeric_zscore(df, name, mean=None, sd=None):\n","    if mean is None:\n","        mean = df[name].mean()\n","    if sd is None:\n","        sd = df[name].std()\n","    df[name] = (df[name] - mean) / sd\n","\n","# Convert all missing values in the specified column to the median\n","def missing_median(df, name):\n","    med = df[name].median()\n","    df[name] = df[name].fillna(med)\n","\n","# Convert all missing values in the specified column to the default\n","def missing_default(df, name, default_value):\n","    df[name] = df[name].fillna(default_value)\n","\n","# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n","def to_xy(df, target):\n","    result = []\n","    for x in df.columns:\n","        if x != target:\n","            result.append(x)\n","    # find out the type of the target column.  Is it really this hard? :(\n","    target_type = df[target].dtypes\n","    target_type = target_type[0] if hasattr(\n","        target_type, '__iter__') else target_type\n","    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n","    if target_type in (np.int64, np.int32):\n","        # Classification\n","        dummies = pd.get_dummies(df[target])\n","        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n","    # Regression\n","    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n","\n","# Nicely formatted time string\n","def hms_string(sec_elapsed):\n","    h = int(sec_elapsed / (60 * 60))\n","    m = int((sec_elapsed % (60 * 60)) / 60)\n","    s = sec_elapsed % 60\n","    return f\"{h}:{m:>02}:{s:>05.2f}\"\n","\n","# Regression chart.\n","def chart_regression(pred, y, sort=True):\n","    t = pd.DataFrame({'pred': pred, 'y': y.flatten()})\n","    if sort:\n","        t.sort_values(by=['y'], inplace=True)\n","    plt.plot(t['y'].tolist(), label='expected')\n","    plt.plot(t['pred'].tolist(), label='prediction')\n","    plt.ylabel('output')\n","    plt.legend()\n","    plt.show()\n","\n","# Remove all rows where the specified column is +/- sd standard deviations\n","def remove_outliers(df, name, sd):\n","    drop_rows = df.index[(np.abs(df[name] - df[name].mean())\n","                          >= (sd * df[name].std()))]\n","    df.drop(drop_rows, axis=0, inplace=True)\n","\n","# Encode a column to a range between normalized_low and normalized_high.\n","def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n","                         data_low=None, data_high=None):\n","    if data_low is None:\n","        data_low = min(df[name])\n","        data_high = max(df[name])\n","    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n","        * (normalized_high - normalized_low) + normalized_low"]},{"cell_type":"markdown","metadata":{"id":"v8hbZedFRqH7"},"source":["Next let's recall one of the models from last week."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SRVND_RURqH7","outputId":"8c8b9eac-aeed-4488-dfca-f5d10b239207"},"outputs":[{"name":"stdout","output_type":"stream","text":["Final score (RMSE): 4.66825008392334\n"]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation\n","from tensorflow.keras.callbacks import EarlyStopping\n","import pandas as pd\n","import io\n","import requests\n","import numpy as np\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","\n","path = \"../ex1/\"\n","\n","filename_read = os.path.join(path,\"auto-mpg.csv\")\n","df = pd.read_csv(filename_read,na_values=['NA','?'])\n","\n","cars = df['name']\n","df.drop('name',1,inplace=True)\n","missing_median(df, 'horsepower')\n","X,y = to_xy(df,\"mpg\")\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n","\n","model = Sequential()\n","model.add(Dense(64, input_dim=X.shape[1], activation='relu'))\n","model.add(Dense(1)) # Output\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","model.fit(X_train,y_train,verbose=0,epochs=200)\n","\n","pred = model.predict(X_test)\n","# Measure RMSE error.\n","score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n","print(\"Final score (RMSE): {}\".format(score))"]},{"cell_type":"markdown","metadata":{"id":"RdqyDaEWRqH9"},"source":["Now the callback is added, with the definition of **monitor** defining early stopping on *loss*.  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Io_YWzMRqH9","outputId":"259080cd-369a-4a1d-856b-8e172a2df007"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/200\n","10/10 - 0s - loss: 38153.0508\n","Epoch 2/200\n","10/10 - 0s - loss: 5697.9268\n","Epoch 3/200\n","10/10 - 0s - loss: 2882.6287\n","Epoch 4/200\n","10/10 - 0s - loss: 1319.1770\n","Epoch 5/200\n","10/10 - 0s - loss: 400.8026\n","Epoch 6/200\n","10/10 - 0s - loss: 372.4380\n","Epoch 7/200\n","10/10 - 0s - loss: 251.9752\n","Epoch 8/200\n","10/10 - 0s - loss: 203.4046\n","Epoch 9/200\n","10/10 - 0s - loss: 204.4814\n","Epoch 10/200\n","10/10 - 0s - loss: 193.0516\n","Epoch 11/200\n","10/10 - 0s - loss: 187.4896\n","Epoch 12/200\n","10/10 - 0s - loss: 183.8933\n","Epoch 13/200\n","10/10 - 0s - loss: 180.0732\n","Epoch 14/200\n","10/10 - 0s - loss: 176.4046\n","Epoch 15/200\n","10/10 - 0s - loss: 171.7619\n","Epoch 16/200\n","10/10 - 0s - loss: 168.7182\n","Epoch 17/200\n","10/10 - 0s - loss: 162.7848\n","Epoch 18/200\n","10/10 - 0s - loss: 157.5928\n","Epoch 19/200\n","10/10 - 0s - loss: 153.0657\n","Epoch 20/200\n","10/10 - 0s - loss: 148.5979\n","Epoch 21/200\n","10/10 - 0s - loss: 146.7766\n","Epoch 22/200\n","10/10 - 0s - loss: 142.1727\n","Epoch 23/200\n","10/10 - 0s - loss: 139.3495\n","Epoch 24/200\n","10/10 - 0s - loss: 138.8910\n","Epoch 25/200\n","10/10 - 0s - loss: 135.1155\n","Epoch 26/200\n","10/10 - 0s - loss: 135.0490\n","Epoch 27/200\n","10/10 - 0s - loss: 132.7910\n","Epoch 28/200\n","10/10 - 0s - loss: 131.9517\n","Epoch 29/200\n","10/10 - 0s - loss: 128.9642\n","Epoch 30/200\n","10/10 - 0s - loss: 127.1835\n","Epoch 31/200\n","10/10 - 0s - loss: 127.4213\n","Epoch 32/200\n","10/10 - 0s - loss: 124.5362\n","Epoch 33/200\n","10/10 - 0s - loss: 122.7517\n","Epoch 34/200\n","10/10 - 0s - loss: 120.6580\n","Epoch 35/200\n","10/10 - 0s - loss: 121.0588\n","Epoch 36/200\n","10/10 - 0s - loss: 119.1201\n","Epoch 37/200\n","10/10 - 0s - loss: 116.7558\n","Epoch 38/200\n","10/10 - 0s - loss: 117.8534\n","Epoch 39/200\n","10/10 - 0s - loss: 114.0055\n","Epoch 40/200\n","10/10 - 0s - loss: 114.9948\n","Epoch 41/200\n","10/10 - 0s - loss: 112.2703\n","Epoch 42/200\n","10/10 - 0s - loss: 110.7344\n","Epoch 43/200\n","10/10 - 0s - loss: 111.5580\n","Epoch 44/200\n","10/10 - 0s - loss: 113.0002\n","Epoch 45/200\n","10/10 - 0s - loss: 109.0078\n","Epoch 46/200\n","10/10 - 0s - loss: 105.1853\n","Epoch 47/200\n","10/10 - 0s - loss: 105.0106\n","Epoch 48/200\n","10/10 - 0s - loss: 104.7342\n","Epoch 49/200\n","10/10 - 0s - loss: 101.1583\n","Epoch 50/200\n","10/10 - 0s - loss: 100.5150\n","Epoch 51/200\n","10/10 - 0s - loss: 97.9273\n","Epoch 52/200\n","10/10 - 0s - loss: 98.4786\n","Epoch 53/200\n","10/10 - 0s - loss: 96.9628\n","Epoch 54/200\n","10/10 - 0s - loss: 94.9301\n","Epoch 55/200\n","10/10 - 0s - loss: 93.9595\n","Epoch 56/200\n","10/10 - 0s - loss: 94.0675\n","Epoch 57/200\n","10/10 - 0s - loss: 96.4375\n","Epoch 58/200\n","10/10 - 0s - loss: 90.6291\n","Epoch 59/200\n","10/10 - 0s - loss: 100.6113\n","Epoch 60/200\n","10/10 - 0s - loss: 92.4752\n","Epoch 61/200\n","10/10 - 0s - loss: 92.2914\n","Epoch 62/200\n","10/10 - 0s - loss: 85.5049\n","Epoch 63/200\n","10/10 - 0s - loss: 92.6228\n","Epoch 64/200\n","10/10 - 0s - loss: 88.4593\n","Epoch 65/200\n","10/10 - 0s - loss: 85.8891\n","Epoch 66/200\n","10/10 - 0s - loss: 89.9630\n","Epoch 67/200\n","10/10 - 0s - loss: 82.2506\n","Epoch 68/200\n","10/10 - 0s - loss: 80.8674\n","Epoch 69/200\n","10/10 - 0s - loss: 77.2562\n","Epoch 70/200\n","10/10 - 0s - loss: 75.6927\n","Epoch 71/200\n","10/10 - 0s - loss: 71.9486\n","Epoch 72/200\n","10/10 - 0s - loss: 71.1033\n","Epoch 73/200\n","10/10 - 0s - loss: 73.5650\n","Epoch 74/200\n","10/10 - 0s - loss: 70.3123\n","Epoch 75/200\n","10/10 - 0s - loss: 70.6965\n","Epoch 76/200\n","10/10 - 0s - loss: 65.7741\n","Epoch 77/200\n","10/10 - 0s - loss: 64.6160\n","Epoch 78/200\n","10/10 - 0s - loss: 70.5251\n","Epoch 79/200\n","10/10 - 0s - loss: 63.9306\n","Epoch 80/200\n","10/10 - 0s - loss: 62.6711\n","Epoch 81/200\n","10/10 - 0s - loss: 62.3065\n","Epoch 82/200\n","10/10 - 0s - loss: 59.9790\n","Epoch 83/200\n","10/10 - 0s - loss: 63.0065\n","Epoch 84/200\n","10/10 - 0s - loss: 59.6531\n","Epoch 85/200\n","10/10 - 0s - loss: 59.2298\n","Epoch 86/200\n","10/10 - 0s - loss: 56.6843\n","Epoch 87/200\n","10/10 - 0s - loss: 57.5357\n","Epoch 88/200\n","10/10 - 0s - loss: 58.4258\n","Epoch 89/200\n","10/10 - 0s - loss: 55.5856\n","Epoch 90/200\n","10/10 - 0s - loss: 55.0267\n","Epoch 91/200\n","10/10 - 0s - loss: 54.0300\n","Epoch 92/200\n","10/10 - 0s - loss: 52.4376\n","Epoch 93/200\n","10/10 - 0s - loss: 51.2877\n","Epoch 94/200\n","10/10 - 0s - loss: 50.3719\n","Epoch 95/200\n","10/10 - 0s - loss: 49.9758\n","Epoch 96/200\n","10/10 - 0s - loss: 48.8882\n","Epoch 97/200\n","10/10 - 0s - loss: 49.4599\n","Epoch 98/200\n","10/10 - 0s - loss: 49.7782\n","Epoch 99/200\n","10/10 - 0s - loss: 47.7371\n","Epoch 100/200\n","10/10 - 0s - loss: 46.2549\n","Epoch 101/200\n","10/10 - 0s - loss: 45.2477\n","Epoch 102/200\n","10/10 - 0s - loss: 45.0041\n","Epoch 103/200\n","10/10 - 0s - loss: 44.8236\n","Epoch 104/200\n","10/10 - 0s - loss: 49.4170\n","Epoch 105/200\n","10/10 - 0s - loss: 43.4735\n","Epoch 106/200\n","10/10 - 0s - loss: 42.0936\n","Epoch 107/200\n","10/10 - 0s - loss: 41.3507\n","Epoch 108/200\n","10/10 - 0s - loss: 41.3856\n","Epoch 109/200\n","10/10 - 0s - loss: 41.5128\n","Epoch 110/200\n","10/10 - 0s - loss: 39.6663\n","Epoch 111/200\n","10/10 - 0s - loss: 38.7415\n","Epoch 112/200\n","10/10 - 0s - loss: 41.8596\n","Epoch 113/200\n","10/10 - 0s - loss: 40.6914\n","Epoch 114/200\n","10/10 - 0s - loss: 37.8461\n","Epoch 115/200\n","10/10 - 0s - loss: 36.4370\n","Epoch 116/200\n","10/10 - 0s - loss: 36.5101\n","Epoch 117/200\n","10/10 - 0s - loss: 36.1756\n","Epoch 118/200\n","10/10 - 0s - loss: 35.5664\n","Epoch 119/200\n","10/10 - 0s - loss: 34.2197\n","Epoch 120/200\n","10/10 - 0s - loss: 35.1951\n","Epoch 121/200\n","10/10 - 0s - loss: 33.9113\n","Epoch 122/200\n","10/10 - 0s - loss: 32.5319\n","Epoch 123/200\n","10/10 - 0s - loss: 33.7143\n","Epoch 124/200\n","10/10 - 0s - loss: 32.4615\n","Epoch 125/200\n","10/10 - 0s - loss: 32.7160\n","Epoch 126/200\n","10/10 - 0s - loss: 32.3670\n","Epoch 127/200\n","10/10 - 0s - loss: 30.7368\n","Epoch 128/200\n","10/10 - 0s - loss: 30.3729\n","Epoch 129/200\n","10/10 - 0s - loss: 30.1077\n","Epoch 130/200\n","10/10 - 0s - loss: 29.1129\n","Epoch 131/200\n","10/10 - 0s - loss: 29.2627\n","Epoch 132/200\n","10/10 - 0s - loss: 28.3686\n","Epoch 133/200\n","10/10 - 0s - loss: 27.8816\n","Epoch 134/200\n","10/10 - 0s - loss: 31.9077\n","Epoch 135/200\n","10/10 - 0s - loss: 32.6484\n","Epoch 136/200\n","10/10 - 0s - loss: 27.1140\n","Epoch 137/200\n","10/10 - 0s - loss: 28.3707\n","Epoch 138/200\n","10/10 - 0s - loss: 25.6960\n","Epoch 139/200\n","10/10 - 0s - loss: 27.6098\n","Epoch 140/200\n","10/10 - 0s - loss: 25.9622\n","Epoch 141/200\n","10/10 - 0s - loss: 26.1483\n","Epoch 142/200\n","10/10 - 0s - loss: 24.5829\n","Epoch 143/200\n","10/10 - 0s - loss: 23.9219\n","Epoch 144/200\n","10/10 - 0s - loss: 23.5073\n","Epoch 145/200\n","10/10 - 0s - loss: 23.7215\n","Epoch 146/200\n","10/10 - 0s - loss: 23.5241\n","Epoch 147/200\n","10/10 - 0s - loss: 23.1202\n","Epoch 148/200\n","10/10 - 0s - loss: 22.4056\n","Epoch 149/200\n","10/10 - 0s - loss: 22.1457\n","Epoch 150/200\n","10/10 - 0s - loss: 21.6704\n","Epoch 151/200\n","10/10 - 0s - loss: 21.7902\n","Epoch 152/200\n","10/10 - 0s - loss: 21.5310\n","Epoch 153/200\n","10/10 - 0s - loss: 21.4722\n","Epoch 154/200\n","10/10 - 0s - loss: 20.7544\n","Epoch 155/200\n","10/10 - 0s - loss: 21.8253\n","Epoch 156/200\n","10/10 - 0s - loss: 21.1777\n","Epoch 157/200\n","10/10 - 0s - loss: 20.6016\n","Epoch 158/200\n","10/10 - 0s - loss: 21.0199\n","Epoch 159/200\n","10/10 - 0s - loss: 19.9298\n","Epoch 160/200\n","10/10 - 0s - loss: 19.9436\n","Epoch 161/200\n","10/10 - 0s - loss: 19.5394\n","Epoch 162/200\n","10/10 - 0s - loss: 18.8471\n","Epoch 163/200\n","10/10 - 0s - loss: 18.3806\n","Epoch 164/200\n","10/10 - 0s - loss: 19.8707\n","Epoch 165/200\n","10/10 - 0s - loss: 17.9103\n","Epoch 166/200\n","10/10 - 0s - loss: 18.0400\n","Epoch 167/200\n","10/10 - 0s - loss: 19.0224\n","Epoch 168/200\n","10/10 - 0s - loss: 18.9855\n","Epoch 169/200\n","10/10 - 0s - loss: 18.3088\n","Epoch 170/200\n","10/10 - 0s - loss: 20.4174\n","Epoch 00170: early stopping\n","Final score (RMSE): 4.390988826751709\n"]}],"source":["model = Sequential()\n","model.add(Dense(64, input_dim=X.shape[1], activation='relu'))\n","model.add(Dense(1)) # Output\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","monitor = EarlyStopping(monitor='loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n","model.fit(X_train,y_train,callbacks=[monitor],verbose=2,epochs=200)\n","pred = model.predict(X_test)\n","# Measure RMSE error.\n","score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n","print(\"Final score (RMSE): {}\".format(score))"]},{"cell_type":"markdown","metadata":{"id":"ird6FXJdRqH-"},"source":["Observe that training has terminated early.  You might experiement with adjusting *min_delta* and *patience* and observe changes in behaviour."]},{"cell_type":"markdown","metadata":{"id":"4Eado79FRqH_"},"source":["## 2. Dropout regularisation\n","\n","Most neural network frameworks implement dropout as a separate layer.  Dropout layers function as a regular, densely connected neural network layer.  The only difference is that the dropout layers will periodically drop some of their neurons during training.  You can use dropout layers on regular feedforward neural networks.\n","\n","The usual hyper-parameters for a dropout layer are the following:\n","\n","* Neuron Count\n","* Activation Function\n","* Dropout Probability\n","\n","The neuron count and activation function hyper-parameters work exactly the same way as their corresponding parameters in the dense layer we studied last week. The neuron count simply specifies the number of neurons in the dropout layer.  The dropout probability indicates the likelihood of a neuron dropping out during the training iteration.  Just as it does for a dense layer, the program specifies an activation function for the dropout layer.\n","\n","![class_9_dropout.png](attachment:class_9_dropout.png)\n","\n","The specified percentage of neurons will be masked during each training step.  All neurons return after training is complete.  To make use of dropout in Keras use the **Dropout** layer and specify a dropout probability.  This is the percent of neurons to be dropped.  Typically this is a low value, such as 0.1."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iQRe7Y0wRqIA","outputId":"08d0053d-7e99-4d58-849a-291dcde4697a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/1000\n","10/10 - 0s - loss: 21154.7441\n","Epoch 2/1000\n","10/10 - 0s - loss: 19572.4727\n","Epoch 3/1000\n","10/10 - 0s - loss: 20680.5859\n","Epoch 4/1000\n","10/10 - 0s - loss: 21043.4688\n","Epoch 5/1000\n","10/10 - 0s - loss: 17379.6016\n","Epoch 6/1000\n","10/10 - 0s - loss: 15036.0391\n","Epoch 7/1000\n","10/10 - 0s - loss: 15061.4326\n","Epoch 8/1000\n","10/10 - 0s - loss: 12802.5459\n","Epoch 9/1000\n","10/10 - 0s - loss: 12276.3135\n","Epoch 10/1000\n","10/10 - 0s - loss: 13513.6377\n","Epoch 11/1000\n","10/10 - 0s - loss: 9924.6152\n","Epoch 12/1000\n","10/10 - 0s - loss: 9693.6523\n","Epoch 13/1000\n","10/10 - 0s - loss: 8254.5488\n","Epoch 14/1000\n","10/10 - 0s - loss: 8511.5508\n","Epoch 15/1000\n","10/10 - 0s - loss: 6954.7295\n","Epoch 16/1000\n","10/10 - 0s - loss: 8178.8760\n","Epoch 17/1000\n","10/10 - 0s - loss: 7519.5991\n","Epoch 18/1000\n","10/10 - 0s - loss: 5768.7109\n","Epoch 19/1000\n","10/10 - 0s - loss: 6386.8755\n","Epoch 20/1000\n","10/10 - 0s - loss: 6398.5962\n","Epoch 21/1000\n","10/10 - 0s - loss: 5029.8008\n","Epoch 22/1000\n","10/10 - 0s - loss: 6477.8823\n","Epoch 23/1000\n","10/10 - 0s - loss: 4925.1577\n","Epoch 24/1000\n","10/10 - 0s - loss: 5318.4570\n","Epoch 25/1000\n","10/10 - 0s - loss: 4269.1050\n","Epoch 26/1000\n","10/10 - 0s - loss: 3920.4141\n","Epoch 27/1000\n","10/10 - 0s - loss: 3903.8948\n","Epoch 28/1000\n","10/10 - 0s - loss: 3685.5515\n","Epoch 29/1000\n","10/10 - 0s - loss: 4402.4937\n","Epoch 30/1000\n","10/10 - 0s - loss: 2905.7520\n","Epoch 31/1000\n","10/10 - 0s - loss: 3283.6482\n","Epoch 32/1000\n","10/10 - 0s - loss: 2924.5154\n","Epoch 33/1000\n","10/10 - 0s - loss: 2713.2131\n","Epoch 34/1000\n","10/10 - 0s - loss: 2617.0930\n","Epoch 35/1000\n","10/10 - 0s - loss: 2569.1575\n","Epoch 36/1000\n","10/10 - 0s - loss: 2104.8237\n","Epoch 37/1000\n","10/10 - 0s - loss: 2168.6997\n","Epoch 38/1000\n","10/10 - 0s - loss: 2287.2017\n","Epoch 39/1000\n","10/10 - 0s - loss: 2347.2053\n","Epoch 40/1000\n","10/10 - 0s - loss: 2220.0564\n","Epoch 41/1000\n","10/10 - 0s - loss: 2323.9529\n","Epoch 00041: early stopping\n","Final score (RMSE): 11.49379825592041\n","Model: \"sequential_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_17 (Dense)             (None, 64)                512       \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 1)                 65        \n","=================================================================\n","Total params: 577\n","Trainable params: 577\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# Keras with Dropout (Regression)\n","\n","from matplotlib.pyplot import figure, show\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import os\n","import numpy as np\n","from sklearn import metrics\n","from scipy.stats import zscore\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.models import Sequential\n","\n","# Convert all missing values in the specified column to the median\n","def missing_median(df, name):\n","    med = df[name].median()\n","    df[name] = df[name].fillna(med)\n","\n","# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n","def to_xy(df, target):\n","    result = []\n","    for x in df.columns:\n","        if x != target:\n","            result.append(x)\n","    # find out the type of the target column.  Is it really this hard? :(\n","    target_type = df[target].dtypes\n","    target_type = target_type[0] if hasattr(\n","        target_type, '__iter__') else target_type\n","    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n","    if target_type in (np.int64, np.int32):\n","        # Classification\n","        dummies = pd.get_dummies(df[target])\n","        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n","    # Regression\n","    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n","\n","path = \"../ex1/\"\n","\n","# Set the desired TensorFlow output level for this example\n","#tf.logging.set_verbosity(tf.logging.ERROR)\n","\n","#read in file, as we have done previously\n","filename_read = os.path.join(path,\"auto-mpg.csv\")\n","df = pd.read_csv(filename_read,na_values=['NA','?'])\n","\n","df.drop('name',1,inplace=True)\n","missing_median(df, 'horsepower')\n","X,y = to_xy(df,\"mpg\")\n","\n","# Split into train/test\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=45)\n","\n","model = Sequential()\n","\n","#model.add(Dropout(0.1)) #applies to layer before ie input here\n","model.add(Dense(64, input_dim=X.shape[1], activation='relu'))\n","model.add(Dropout(0.1))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","monitor = EarlyStopping(monitor='loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n","model.fit(X_train,y_train,callbacks=[monitor],verbose=2,epochs=1000)\n","pred = model.predict(X_test)\n","# Measure RMSE error.  RMSE is common for regression.\n","score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n","print(\"Final score (RMSE): {}\".format(score))\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"3f31NpxjRqIA"},"source":["Notice that on a typical run, Dropout here leads to shorter training time, though not necessarily better results."]},{"cell_type":"markdown","metadata":{"id":"YK6eNf27RqIB"},"source":["## 3. L1 (Lasso) regularization\n","\n","L1 Regularization, also called LASSO (Least Absolute Shrinkage and Selection Operator) is used to create sparsity in the neural network. In other words, the L1 algorithm will push many weight connections to near 0.  Dropping weighted connections will create a sparse neural network.\n","\n","Feature selection is a useful by product of sparse neural networks. Features are the values that the training set provides to the input neurons.  Once all the weights of an input neuron reach 0, you might conclude that the feature is unnecessary.  If your data set has a large number of input features that may not be needed, L1 regularization can help the neural network detect and ignore unnecessary features.\n","\n","L1 is implemented by adding the following error to the objective to minimize:\n","\n","$$ E_1 = \\alpha \\sum_w{ |w| } $$\n","\n","The following code demonstrates Lasso regression.  Notice the effect on the coefficients, four of which are close to zero."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZrULU-rYRqIB","outputId":"a3c3801f-7dee-4b45-e91f-cc76e39c206e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Final score (RMSE): 3.0604023933410645\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>coef</th>\n","      <th>positive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>cylinders</th>\n","      <td>-0.012994</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>weight</th>\n","      <td>-0.007328</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>horsepower</th>\n","      <td>-0.002715</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>displacement</th>\n","      <td>0.011601</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>acceleration</th>\n","      <td>0.114391</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>origin</th>\n","      <td>0.708222</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>year</th>\n","      <td>0.777480</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  coef  positive\n","cylinders    -0.012994     False\n","weight       -0.007328     False\n","horsepower   -0.002715     False\n","displacement  0.011601      True\n","acceleration  0.114391      True\n","origin        0.708222      True\n","year          0.777480      True"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Intercept: [-18.50667]\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAagAAAD4CAYAAAC5S3KDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAYcElEQVR4nO3deZhldX3n8feHZVRoBJTWcRBsRYS0qCAFgsqiEkJcMaCCy8giPThGXAKZ+LiMG655JI5RsWVMYyaigqDGUdmkaUAaqYZeAAWVZaLjmEYICoZF+M4f9zRcylq7a/lV9fv1PPXUub/zO7/zvae661O/c889N1WFJEmt2WSmC5AkaTgGlCSpSQaUJKlJBpQkqUkGlCSpSZvNdAFzxXbbbVcLFiyY6TIkadZYsWLFrVU1f6T1BtQkWbBgAYODgzNdhiTNGkluGW29p/gkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElN8jLzRiUzXYEkjW0qPxDDGZQkqUkGlCSpSQaUJKlJBpQkqUkGlCSpSQbUOCXZdKZrkKSNyZwMqCQfSvK2vscnJzkhyUlJrkyyOskH+tZ/M8mKJNcmWdTXfmeSDya5Ath3mp+GJG3U5mRAAf8TeCNAkk2AI4BfAzsDewO7A3sm2b/rf0xV7QkMACckeWzXviVwTVU9p6ouHbqTJIuSDCYZXLt27dQ+I0nayMzJgKqqm4HfJNkDOBi4Gtirb/kqYFd6gQW9UFoFLAd26Gu/H/jGKPtZXFUDVTUwf/6In7klSVoPc/lOEqcBRwH/EfgS8CLgo1X1hf5OSQ4EDgL2rarfJ1kKPLJbfXdV3T9dBUuSHjInZ1Cdc4BD6M2czu2+jkkyDyDJ9kkeB2wN3N6F067APjNVsCTpIXN2BlVV9ya5CPi3bhZ0XpI/AS5P70Z3dwKvB74PHJ9kNXA9vdN8kqQZNmcDqrs4Yh/gVevaqurTwKeH6f7nw41RVfOmpjpJ0ljm5Cm+JAuBnwEXVtVPZ7oeSdLEzckZVFVdBzxlpuuQJK2/ORlQc8FUfsaKJM0Gc/IUnyRp9jOgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElN8uM2GtX7VHpJmri58nE9zqAkSU0yoCRJTTKgJElNMqAkSU2a8wGV5LtJthmjzweTHDRdNUmSxjZnr+JLEiBV9eKx+lbV+6ahJEnSBMzqGVSSdya5pvt6e5IFSX6c5HPAVcAOSW5Osl3X/71JfpLk/CRnJDmxa1+S5PBu+eYkH0hyVZI1SXaduWcoSRuvWRtQSfYEjgaeA+wDHAdsC+wCfLmq9qiqW/r6DwCHAXsAfwEMjDL8rVX1bODzwImj1LAoyWCSwbVr127oU5Ik9Zm1AQU8Hzinqu6qqjuBs4H9gFuqavkI/b9VVf9eVb8D/nmUsc/uvq8AFozUqaoWV9VAVQ3Mnz9/vZ6EJGl4szmgRrrXwl0T7D+ce7rv9zOHX6eTpJbN5oBaBhyaZIskWwKvBC4Zpf+lwMuSPDLJPOAl01GkJGn9zNrZQVVdlWQJ8KOu6TTg9lH6X5nk28Aq4BZgELhjquuUJK2f1Fy5q+A4JJlXVXcm2YLeDGxRVV01GWMPDAzU4ODgZAwFeLNYSetvtvxaT7Kiqka8YG3WzqDW0+IkC4FHAqdPVjhJkibfRhVQVfXama5BkjQ+G1VAzSazZYouSVNlNl/FJ0mawwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKT/LiNRs22T9T140EkTTZnUJKkJhlQkqQmGVCSpCYZUJKkJjUZUEmWJhmYpLEOTbKw7/EHkxw0GWNLkqZOkwE1UUk2HWX1ocCDAVVV76uqC6a+KknShtiggEryzSQrklybZFHXdkiSq5KsSnJh1zYvyT8kWZNkdZLDuvaDk1ze9T8zybxh9jFsnyQ3J3lfkkuBVyU5LsmV3X6/kWSLJM8FXg58MsnKJDslWZLk8G6MFyW5uqvrS0ke0Tf2B7p9rkmy64YcJ0nSxG3oDOqYqtoTGABOSPJ44IvAYVX1LOBVXb/3AndU1TOq6pnAD5JsB7wHOKiqng0MAu/sH3wcfe6uqudX1VeBs6tqr26/PwaOraofAt8GTqqq3avq531jPxJYArymqp5B7z1hb+4b+9Zun58HThzuySdZlGQwyeDatWsnduQkSaPa0IA6IckqYDmwA7AIWFZVNwFU1W1dv4OAz67bqKpuB/ahd+rtsiQrgTcCTxoy/lh9vta3vFuSS5KsAV4HPH2M2ncBbqqqG7rHpwP7960/u/u+Algw3ABVtbiqBqpqYP78+WPsTpI0Eet9J4kkB9ILnn2r6vdJlgKr6P3i/6PuwNB7DQQ4v6qOHG03Y/S5q295CXBoVa1KchRw4FhPYYz193Tf78c7bkjStNuQGdTWwO1dOO1Kb7bzCOCAJE8GSPKYru95wF+u2zDJtvRmXc9L8tSubYskTxuyj/H0WWcr4FdJNqc3g1rnd926oX4CLFg3NvAG4OJxPG9J0jTYkID6PrBZktXAh+iFyVp6p/nO7k79rTsF92Fg2yTXdO0vqKq1wFHAGd0Yy4GHXYwwnj593gtcAZxPL3zW+SpwUncxxE59Y98NHA2c2Z0WfAA4dX0OhCRp8qW8y+ekGBgYqMHBwUkbz5vFSprrkqyoqhHf8zon3gclSZp7DChJUpO8Oq1RnjKTtLFzBiVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkh+30aihn6jrx29I2tg4g5IkNcmAkiQ1yYCSJDXJgJIkNWnCF0kkeT9wJ/BoYFlVXTDB7Q8ETqyql05039MtyaHADVV13UzXIkkbm/WeQVXV+yYaTrPQocDCmS5CkjZG4wqoJO9Ocn2SC4BdurYlSQ7vlj+W5Lokq5P8bd/6U5NckuSGJH80Y0qyd5IfJrm6+75u7E2T/G2SNd2Yb+3a90xycZIVSc5N8oSufWmSU5IsS/LjJHslOTvJT5N8uG9/r0/yoyQrk3whyaZd+51JTk6yKsnyJI9P8lzg5cAnu/47bcBxliRN0Jin+JLsCRwB7NH1vwpY0bf+McArgV2rqpJs07f5AuAAYCfgoiRPHTL8T4D9q+oPSQ4CPgIcBiwCngzs0a17TJLNgc8Ar6iqtUleA5wMHNONdW9V7Z/kbcC3gD2B24CfJzkFeBzwGuB5VXVfks8BrwO+DGwJLK+qdyf5BHBcVX04ybeB71TVWSMcm0Vdrey4445jHUpJ0gSM5zWo/YBzqur3AN0v7X6/Be4GTkvyv4Hv9K37elU9APw0yY3ArkO23Ro4PcnOQAGbd+0HAadW1R8Aquq2JLsBuwHnp/cu1k2BX/WNta6uNcC1VfWrrt4bgR2A59MLrSu77R8F/Gu3zb19da8A/nQcx4WqWgwsBhgYGPCttJI0icZ7kcSIv3y7Gc7ewIvozbT+EnjhCNsNffwh4KKqemWSBcDSrj3D9A294Nl3hFLu6b4/0Le87vFm3fanV9W7htn2vqoH79VwP95hQ5Jm3Hheg1oGvDLJo5JsBbysf2WSecDWVfVd4O3A7n2rX5Vkk+71m6cA1w8Ze2vgl93yUX3t5wHHJ9ms28djum3nJ9m3a9s8ydPHUf86FwKHJ3ncujGTPGmMbX4HbDWBfUiSJsmYAVVVVwFfA1YC3wAuGdJlK+A7SVYDFwPv6Ft3fdf2PeD4qrp7yLafAD6a5DJ6p+zWOQ34P8DqJKuA11bVvcDhwMe7tpXAc8f1LHvP4zrgPcB5Xa3nA08YY7OvAid1F3F4kYQkTaPUFN2FNMkSRrnAYK4ZGBiowcHBSRvPm8VKmuuSrKiqgZHWeycJSVKTpuxigKo6aqrGliTNfV6t1ihP6Una2HmKT5LUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA6pFQz9OV5I2QgaUJKlJBpQkqUkGlCSpSQaUJKlJkxJQSRYkuWYyxpIkCRqYQSXZbKZrGI/ZUqckzRWTGVCbJvlikmuTnJfkUUl2T7I8yeok5yTZFiDJ0iQfSXIx8LYkr0pyTZJVSZZ1fTZN8skkV3bb/5eu/cAky7rxrktyapJNunVHJlnTjfXxru3VST7VLb8tyY3d8k5JLu2W90xycZIVSc5N8oTh6pzEYyVJGsNkzgp2Bo6squOSfB04DPhr4K1VdXGSDwL/HXh713+bqjoAIMka4M+q6pdJtunWHwvcUVV7JXkEcFmS87p1ewMLgVuA7wN/keSHwMeBPYHbgfOSHAosA07qttsP+E2S7YHnA5ck2Rz4DPCKqlqb5DXAycAxQ+scKskiYBHAjjvuuL7HTZI0jMkMqJuqamW3vALYid4v94u7ttOBM/v6f61v+TJgSRdsZ3dtBwPPTHJ493hreiF4L/Cjqlo3EzqDXtjcByytqrVd+z8B+1fVN5PMS7IVsAPwFWB/emF1NrALsBtwfnpvkN0U+NUIdT5MVS0GFgMMDAzU6IdHkjQRkxlQ9/Qt3w9sM1LHzl3rFqrq+CTPAV4CrEyyOxB6s69z+zdKciAwNAyq6z+Sy4GjgeuBS+jNjvYF/grYEbi2qvYdq05J0vSZyosk7gBuT7Jf9/gNwMXDdUyyU1VdUVXvA26lN9M5F3hzdwqOJE9LsmW3yd5Jnty99vQa4FLgCuCAJNsl2RQ4sm9/y4ATu+9XAy8A7qmqO+iF1vwk+3b72TzJ0yfvMEiS1sdUX5n2RuDUJFsAN9KbxQznk0l2pjcLuhBYBawGFgBXpXfubS1waNf/cuBjwDPohc45VfVAkncBF3XjfLeqvtX1v4Re6C2rqvuT/AvwE4Cqurc7jfg/kmxN75j8HXDtJB0DSdJ6SNXseumkO8V3YlW9dKZr6TcwMFCDg4OTM1gCs+znIkkTlWRFVQ2MtH7G3wclSdJwZt2bT6tqKbB0hsuQJE0xZ1At8vSeJBlQkqQ2GVCSpCYZUJKkJhlQkqQmGVCSpCYZUJKkJhlQkqQmGVCSpCYZUJKkJhlQkqQmGVCSpCYZUJKkJhlQkqQmGVCSpCbNus+DmtOSh5b9yA1JGzlnUJKkJhlQkqQmGVCSpCYZUJKkJs3pgEpyWpKFY/RZkuTwYdoXJHnt1FUnSRrNnA6oqnpTVV23npsvAAwoSZohsyKgkvx1khO65VOS/KBbflGS/5Xk4CSXJ7kqyZlJ5nXrlyYZ6JaPTXJD1/bFJH/ft4v9k/wwyY19s6mPAfslWZnkHdP4dCVJzJKAApYB+3XLA8C8JJsDzwfWAO8BDqqqZwODwDv7N07yn4D3AvsAfwrsOmT8J3RjvZReMAH8DXBJVe1eVacMV1SSRUkGkwyuXbt2A5+iJKnfbAmoFcCeSbYC7gEupxdU+wH/DiwELkuyEngj8KQh2+8NXFxVt1XVfcCZQ9Z/s6oe6E4HPn68RVXV4qoaqKqB+fPnr9cTkyQNb1bcSaKq7ktyM3A08ENgNfACYCfgJuD8qjpylCEyyjrohd54+0qSpsFsmUFB7zTfid33S4DjgZXAcuB5SZ4KkGSLJE8bsu2PgAOSbJtkM+Cwcezvd8BWk1W8JGliZlNAXULvtaLLq+rXwN30XiNaCxwFnJFkNb3AethrTFX1S+AjwBXABcB1wB1j7G818Ickq7xIQpKmX2ojuSlpknlVdWc3gzoH+FJVnTNZ4w8MDNTg4OCGDeLNYiVtRJKsqKqBkdbPphnUhnp/dxHFNfRet/rmDNcjSRrFrLhIYjJU1YkzXYMkafw2moCaFTytJ0kP2phO8UmSZhEDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkPw+qBf0f9b6Onw0laSPnDEqS1CQDSpLUJANKktSkWRFQSZYkObxbPi3Jwgluf+fUVCZJmiqz7iKJqnrTVI6fJECq6oGp3I8kaXQzOoNK8p+TrE6yKsk5SW5Ksnm37tFJbl73uG+bpUkGuuU7k5zcbb88yeO79icnuTzJlUk+NGT7k7r21Uk+0LUtSPLjJJ8DrgJ26GZt1yRZk+Qd03E8JEkPmbGASvJ04N3AC6vqWcCxwFLgJV2XI4BvVNV9owyzJbC8234ZcFzX/mng81W1F/D/+vZ5MLAzsDewO7Bnkv271bsAX66qPYDtgO2rareqegbwDyM8h0VJBpMMrl27dmIHQJI0qpmcQb0QOKuqbgWoqtuA04Cju/VHM0Iw9LkX+E63vAJY0C0/DzijW/7Hvv4Hd19X05sp7UovsABuqarl3fKNwFOSfCbJIcBvh9t5VS2uqoGqGpg/f/4YpUqSJmImX4MK8LB3o1bVZd3ptgOATavqmjHGuK/qwXe03s/Dn89w73QN8NGq+sLDGpMFwF19ddye5FnAnwFvAV4NHDPmM5IkTZqZnEFdCLw6yWMBkjyma/8yvdnPWLOn0VxG7xQhwOv62s8Fjkkyr9vn9kkeN3TjJNsBm1TVN4D3As/egFokSethxgKqqq4FTgYuTrIK+FS36p+AbXnoFN36eBvwliRXAlv37fM84CvA5UnWAGcBWw2z/fbA0iQrgSXAuzagFknSekg1ds+37v1Or6iqN8x0LRMxMDBQg4OD67ex9+KTtBFKsqKqBkZa39T7oJJ8Bvhz4MUzXYskaWY1FVBV9daZrkGS1IamAmqj5ek8Sfojs+JefJKkjY8BJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJalJztzqarZKsBW6ZxCG3A26dxPEmS6t1Qbu1tVoXtFtbq3VBu7W1WheMXNuTqmrEzyoyoBqVZHC0e1TNlFbrgnZra7UuaLe2VuuCdmtrtS5Y/9o8xSdJapIBJUlqkgHVrsUzXcAIWq0L2q2t1bqg3dparQvara3VumA9a/M1KElSk5xBSZKaZEBJkppkQM2wJIckuT7Jz5L8zTDrH5Hka936K5IsaKSu/ZNcleQPSQ6fjprGWdc7k1yXZHWSC5M8qaHajk+yJsnKJJcmWdhKbX39Dk9SSablcuVxHLOjkqztjtnKJG+ajrrGU1vX59Xdv7drk3ylhbqSnNJ3vG5I8m/TUdc4a9sxyUVJru7+j47+6elV5dcMfQGbAj8HngL8B2AVsHBIn/8KnNotHwF8rZG6FgDPBL4MHN7Q8XoBsEW3/ObpOF4TqO3RfcsvB77fSm1dv62AZcByYKCFuoCjgL+fjuO0HrXtDFwNbNs9flwLdQ3p/1bgSw0ds8XAm7vlhcDNo43pDGpm7Q38rKpurKp7ga8CrxjS5xXA6d3yWcCLkmSm66qqm6tqNfDAFNcy0bouqqrfdw+XA09sqLbf9j3cEpiuK5TG8+8M4EPAJ4C7G6trJoyntuOAz1bV7QBV9a+N1NXvSOCMaagLxldbAY/ulrcG/u9oAxpQM2t74F/6Hv+iaxu2T1X9AbgDeGwDdc2EidZ1LPC9Ka3oIeOqLclbkvycXhCc0EptSfYAdqiq70xTTeOqq3NYdzrorCQ7TE9p46rtacDTklyWZHmSQxqpC4Du9PaTgR9MQ10wvtreD7w+yS+A79Kb4Y3IgJpZw82Ehv5VPZ4+k20m9jke464ryeuBAeCTU1pR3y6Hafuj2qrqs1W1E/DfgPdMeVU9o9aWZBPgFOCvpqmeB3c9TNvQY/bPwIKqeiZwAQ+dTZhq46ltM3qn+Q6kN1M5Lck2DdS1zhHAWVV1/xTW0288tR0JLKmqJwIvBv6x+/c3LANqZv0C6P+L8In88ZT3wT5JNqM3Lb6tgbpmwrjqSnIQ8G7g5VV1T0u19fkqcOiUVvSQsWrbCtgNWJrkZmAf4NvTcKHEmMesqn7T9zP8IrDnFNc07tq6Pt+qqvuq6ibgenqBNdN1rXME03d6D8ZX27HA1wGq6nLgkfRuJDu86XjxzK8RX1TcDLiR3jR83YuKTx/S5y08/CKJr7dQV1/fJUzfRRLjOV570HuhducGf5Y79y2/DBhspbYh/ZcyPRdJjOeYPaFv+ZXA8laOGXAIcHq3vB2901uPnem6un67ADfT3YyhoWP2PeCobvlP6AXYiDVOS+F+jfpDfTFwQ/dL9d1d2wfp/fUPvb8wzgR+BvwIeEojde1F7y+mu4DfANc2UtcFwK+Bld3Xtxv6WX4auLar66LRQmK6axvSd1oCapzH7KPdMVvVHbNdWzlm9E5pfQq4DlgDHNFCXd3j9wMfm65jNYFjthC4rPt5rgQOHm08b3UkSWqSr0FJkppkQEmSmmRASZKaZEBJkppkQEmSmmRASZKaZEBJkpr0/wGc3+l42MRneQAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["import sklearn\n","from sklearn.linear_model import Lasso\n","\n","# Simple function to evaluate the coefficients of a regression\n","%matplotlib inline\n","from IPython.display import display, HTML\n","\n","def report_coef(names,coef,intercept):\n","    r = pd.DataFrame( { 'coef': coef, 'positive': coef>=0  }, index = names )\n","    r = r.sort_values(by=['coef'])\n","    display(r)\n","    print(\"Intercept: {}\".format(intercept))\n","    r['coef'].plot(kind='barh', color=r['positive'].map({True: 'b', False: 'r'}))\n","\n","# Create linear regression\n","regressor = Lasso(random_state=0,alpha=0.1)\n","\n","# Fit/train LASSO\n","regressor.fit(X_train,y_train)\n","# Predict\n","pred = regressor.predict(X_test)\n","\n","# Measure RMSE error.  RMSE is common for regression.\n","score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n","print(\"Final score (RMSE): {}\".format(score))\n","\n","names = list(df.columns.values)\n","names.remove(\"mpg\")\n","report_coef(\n","  names,\n","  regressor.coef_,\n","  regressor.intercept_)\n"]},{"cell_type":"markdown","metadata":{"id":"ZUSn_KaWRqIC"},"source":["## 4. L2 (Ridge) regularization\n","\n","You should use Tikhonov/Ridge/L2 regularization when you are less concerned about creating a sparce network and are more concerned about low weight values.  The lower weight values will typically lead to less overfitting.\n","\n","$$ E_2 = \\alpha \\sum_w{ w^2 } $$\n","\n","Like the L1 algorithm, the $\\alpha$ value determines how important the L2 objective is compared to the neural networkâ€™s error.  Typical L2 values are below 0.1 (10%).  The main calculation performed by L2 is the summing of the squares of all of the weights.  The bias values are not summed."]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"hbQnuZBpRqIN"},"source":["## 5. Keras and L1/L2\n","\n","L1 and L2 regularization are two common regularization techniques that can reduce the effects of overfitting.  The regularization algorithm is attached to the training algorithm by adding an additional objective.  \n","\n","As discussed above, both of these algorithms work by adding a weight penalty to the neural network training.  This penalty encourages the neural network to keep the weights to small values, and L1 and L2 calculate this penalty differently.  For gradient-descent-based algorithms, such as backpropagation, you can add this penalty calculation to the calculated gradients.\n","\n","Both L1 and L2 work differently in the way that they penalize the size of a weight.  L2 will force the weights into a pattern similar to a Gaussian distribution; the L1 will force the weights into a pattern similar to a Laplace distribution, as demonstrated the following:\n","\n","![L1 vs L2](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_9_l1_l2.png \"L1 vs L2\")\n","\n","As you can see, L1 algorithm is more tolerant of weights further from 0, whereas the L2 algorithm is less tolerant.  You also need to note that both L1 and L2 count their penalties based only on weights; they do not count penalties on bias values.\n","\n","The code below demonstrates that regularizers can be added to a layer in a neural network (and can be applied to the weight (which is slightly more usual) or to the activation function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eDg-ArdPRqIN","outputId":"ffea1a86-297b-4a3b-ec88-e832089e5c82"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 00047: early stopping\n","Final score (RMSE): 3.7053940296173096\n"]}],"source":["from tensorflow.keras import regularizers\n","\n","filename_read = os.path.join(path,\"auto-mpg.csv\")\n","df = pd.read_csv(filename_read,na_values=['NA','?'])\n","\n","df.drop('name',1,inplace=True)\n","missing_median(df, 'horsepower')\n","X,y = to_xy(df,\"mpg\")\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n","\n","model = Sequential()\n","model.add(Dense(64, input_dim=X.shape[1], activation='relu',kernel_regularizer=regularizers.l1(0.01)))\n","#model.add(Dense(64, input_dim=x.shape[1], activation='relu',activity_regularizer=regularizers.l2(0.01)))\n","#model.add(Dense(64, input_dim=x.shape[1], activation='relu',\n","#                kernel_regularizer=regularizers.l2(0.01),\n","#                activity_regularizer=regularizers.l1(0.01),activation='relu'))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","monitor = EarlyStopping(monitor='loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n","model.fit(X_train,y_train,callbacks=[monitor],verbose=0,epochs=1000)\n","pred = model.predict(X_test)\n","# Measure RMSE error.\n","score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n","print(\"Final score (RMSE): {}\".format(score))"]},{"cell_type":"markdown","metadata":{"id":"it8k45-nRqIO"},"source":["The final version of this code that we shall look at is below.  This has two differences.\n"," - The first is that the call to fit includes \"validation_split\".  In these examples so far, we have simply split our data into training data and testing data.  We might well want to split data into training, validation and testing.  validation_split allows a proportion of the training data to be held back to validation.  It can be interesting to see whether the validation results follow the training results, which would be an indication of a model with good generalisation\n"," - The second is that code has been added to plot training.  Here, epochs is plotted against loss/val_loss.  Notice that the call to fit is now giving a return value, and that represents training information (it's called \"training_trace\" in this example).  From this we can access loss and val_loss, the latter being the error on the validation data.\n","\n","Finally, note that early stopping might perhaps instead have been defined on val_loss, rather than loss."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qWNdhsZ_RqIO","outputId":"b6ca7737-8aa7-48ac-fca2-aa41b1f6da8b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 00035: early stopping\n","Final score (RMSE): 4.988840579986572\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 720x720 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["model = Sequential()\n","model.add(Dense(64, input_dim=X.shape[1], activation='relu',kernel_regularizer=regularizers.l1(0.01)))\n","#model.add(Dense(64, input_dim=x.shape[1], activation='relu',activity_regularizer=regularizers.l2(0.01)))\n","#model.add(Dense(64, input_dim=x.shape[1], activation='relu',\n","#                kernel_regularizer=regularizers.l2(0.01),\n","#                activity_regularizer=regularizers.l1(0.01),activation='relu'))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","monitor = EarlyStopping(monitor='loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n","#note the return here, with the data from training stroed in training_trace\n","#also note the validation split\n","training_trace = model.fit(X_train,y_train,callbacks=[monitor],validation_split=0.25,verbose=0,epochs=1000)\n","pred = model.predict(X_test)\n","# Measure RMSE error.\n","score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n","print(\"Final score (RMSE): {}\".format(score))\n","\n","## plot the loss on the training data, and also the validation data\n","plt.figure(figsize=(10,10))\n","\n","plt.plot(training_trace.history['loss'])\n","plt.plot(training_trace.history['val_loss'])\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"loss\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UCHUlV50RqIP"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}